# Chapter 5-2 교차 검증과 그리드 서치 - 실습

## 0. 소개

이번 글에서는 새로운 모델을 배우는 것이 아닌 모델이 좋은 성능을 내기 위해서 데이터를 준비하고 모델의 하이퍼파라미터 값을 찾는 방법을 배운다. 세부 목차는 다음과 같다.

1. 검증 세트 분리해보기 
2. 교차 검증 - 검증 세트로 인한 훈련 세트 부족 문제 해결하기
3. 그리드 서치와 랜덤 서치 - 하이퍼파라미터 튜닝하기

## 1. 검증 세트 분할하기

검증 세트를 직접 분할할 때는 훈련/테스트 세트를 분할할 때 사용했던 train_test_split 메서드를 두 번 사용해서 분할한다.


```python
# load data
import pandas as pd
wine = pd.read_csv('https://bit.ly/wine_csv_data')
```


```python
# separate data
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()
```


```python
# split data to train/test and input/target
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)
```


```python
# split data to train and validatation
sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)
```


```python
# check data size
print(sub_input.shape, val_input.shape, test_input.shape)
```

    (4157, 3) (1040, 3) (1300, 3)
    

* 위에서 데이터를 분리할 때 20%씩을 나누었다. 사실, 20%씩 나누면 검증 세트는 $0.8 \times 0.2 = 0.16$으로 20%가 안된다. 비율을 정확히 맞추어도 되지만, 성능에 큰 차이가 없어서 이런 방식이 널리 통용된다.

이제 훈련 데이터로 모델을 훈련하고 검증 데이터로 평가를 해보자.


```python
# trian model
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)
```




    DecisionTreeClassifier(random_state=42)




```python
# evaluation with validation data set
print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))
```

    0.9971133028626413
    0.864423076923077
    

# 2. 교차 검증 

검증 세트를 떼어 놓게 되면 모델을 훈련하는 훈련 세트가 줄어드는 문제가 생긴다. 이에 대한 해결방안인 교차 검증을 해보자. 사이킷런에는 교차 검증 함수로 cross_validate()를 제공한다. 첫 번째 매개변수로 평가할 모델 객체를 전달하고 검증 세트를 떼어 내지 않은 훈련 세트 전체를 전달하면 된다. cross_validate()는 기본적으로 5-폴드 교차 검증을 수행한다. cross_validate()는 딕셔너리를 출력하며, 키는 다음과 같다.

1. fit_time : 모델을 훈련하는 시간
2. score_time : 검증하는 시간
3. test_time : 검증 점수


```python
# cross validation
from sklearn.model_selection import cross_validate
scores = cross_validate(dt, train_input, train_target)
print(scores)
```

    {'fit_time': array([0.02991939, 0.01096749, 0.0099721 , 0.01096964, 0.01196933]), 'score_time': array([0.00199819, 0.0009973 , 0.        , 0.00199533, 0.00099635]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
    

교차 검증의 최종 점수는 test_score 키에 담긴 5개의 점수를 평균하여 얻을 수 있다. 주의할 것은 이름은 test_score이지만 검증 폴드의 점수라는 것이다.

* 사이킷런은 cross_validate() 함수의 전신인 cross_val_score() 함수도 있지만, 이 함수는 cross_validate() 함수 결과 중 test_score 값만 반환한다.


```python
# cross validation result 
import numpy as np
print(np.mean(scores['test_score']))
```

    0.855300214703487
    

## 2-1. 분할기 지정해주기

앞서 직접 검증 세트를 분할할 때는 train_test_split 함수가 자동으로 데이터를 섞어서 분할해주었다. 그러나, cross_validate() 함수는 폴드를 나눌 때 훈련 세트를 섞지 않기 때문에 분할기(spliter)를 지정해주어야 한다. 기본적으로 첫 번째 매개변수로 전달한 모델 객체가 회귀 모델이면 KFold 분할기를 분류 모델이면 StratifiedKFold를 사용한다. 다음은 아무런 설정을 하지 않은 앞의 코드와 동일하다.


```python
# same setting 
from sklearn.model_selection import StratifiedKFold
scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
```

    0.855300214703487
    

만약 훈련 세트를 섞고 10-폴드 교차 검증을 수행하려면 다음과 같은 StratifiedKFold의 매개변수를 설정해야한다. 

1. n_splits : 몇 폴드 교차 검증을 할지 설정하는 매개변수
2. shuffle : 훈련 세트를 섞어서 폴드를 나눌지 설정하는 매개변수


```python
#10-fold cross validation with shuffle train set
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) 
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```

    0.8574181117533719
    

* KFold도 위와 같은 방식으로 사용할 수 있다.

이제 교차 검증에 대해서 이해했으므로 결정 트리의 매개변수를 변경하며 좋은 성능을 내는 모델을 찾아보자.

# 3. 하이퍼파라미터 튜닝 - 그리드 서치

사이킷런에서 제공하는 그리드 서치는 GridSearchCV 클래스를 통해 구현할 수 있으며 이 클래스는 하이퍼파라미터 탐색과 교차 검증을 한 번에 수행한다. 즉, 별도로 cross_validate() 함수를 호출할 필요가 없다. 

예시를 통해서 사용 방법을 익혀보기 위해서, 결정 트리 모델에서 min_impurity_decrease 매개변수의 최적값을 찾아보자.

## Step1. 매개변수 설정

먼저, GridSearchCV 클래스를 임포트하고 탐색할 매개변수와 탐색할 값의 리스트를 딕셔너리로 만든다.


```python
# import class and make the set of parameters what we will experiment with
from sklearn.model_selection import GridSearchCV
params = {'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}
```

## Step2. 그리드 서치 객체 만들기

다음으로, GridSearchCV 클래스에 탐색 대상 모델과 params 변수를 전달하여 그리드 서치 객체를 만든다. 

GridSearchCV의 cv 매개변수 기본값은 5이다. 즉, 5-폴드 교차 검증을 수행한다. 즉, 파라미터를 5개를 설정했으므로 $5 \times 5 = 25$개의 모델을 훈련한다. 

GridSearchCV의 n_jobs 매개변수는 병렬 실행에 사용할 CPU 코어 수를 지정하는 것으로 기본값은 1이다. -1로 설정하면 시스템에 있는 모든 코어를 사용한다. 


```python
# make grid search object
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=None)
```

## Step3. 그리드 서치 실행하기

모델을 훈련하는 것처럼 그리드 서치 객체에 fit() 메서드를 호출하면 그리드 서치를 실행한다.


```python
# grid search
gs.fit(train_input, train_target)
```




    GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                 param_grid={'min_impurity_decrease': [0.0001, 0.0002, 0.0003,
                                                       0.0004, 0.0005]})



>**오류 해결하기**
그리드 서치 객체를 만들 때, n_jobs의 값을 정수로 설정했을 때 아래와 같은 오류 메세지가 떴다. 이럴 때는 None으로 지정하고 학습해야한다.
> TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.


## Step4. 최적의 하이퍼파라미터 확인하기

교차 검증에서 최적의 하이퍼파라미터를 찾으면 전체 훈련 세트로 모델을 다시 만들어야 한다. 사이킷런의 그리드 서치는 훈련이 끝나면 검증 점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련 세트에서 자동으로 다시 모델을 훈련한다. 이 모델은 훈련을 완료한 그리드 서치 객체의 best_esimator_ 속성에 저장되어 있다. 이 모델을 일반 모델처럼 똑같이 사용할 수 있다. 


```python
# the best model
dt = gs.best_estimator_
print(dt.score(train_input, train_target))
```

    0.9615162593804117
    

그리드 서치로 찾은 최적의 매개변수는 best_params_ 속성에 저장되어 있다.


```python
# the best parameter 
print(gs.best_params_)
```

    {'min_impurity_decrease': 0.0001}
    

**확인해보기**
각 매개변수에서 수행한 교차 검증의 평균 점수는 cv_results_ 속성의 'mean_test_score'키에 저장되어 있다. 5번의 교차 검증으로 얻은 점수를 출력해보자.


```python
# check cross validation score
print(gs.cv_results_['mean_test_score'])
```

    [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
    

넘파이 argmax() 함수를 사용하면 가장 큰 값의 인덱스를 추출할 수 있다. 이를 이용해서 최적의 파라미터값을 출력해보자.


```python
# the best parameter
best_index = np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])
```

    {'min_impurity_decrease': 0.0001}
    

**그리드 서치 정리**

1. 탐색할 매개변수 지정 후 딕셔너리로 만들기
2. 그리드 서치 객체 만들기 - 모델, 탐색할 매개변수, CPU 설정
3. 훈련 데이터로 그리드 서치 실행하기 - fit() 메서드
4. 최상의 파라미터와 최상의 파라미터로 학습된 모델 얻기 - best_params_, best_estimator_

## 여러 가지 하이퍼파라미터 튜닝해보기

그럼, 조금 더 복잡하게 3가지 파라미터에 대해서 최상의 파라미터를 찾는 그리드 서치를 진행해보자. 여기서 찾아볼 파라미터는 다음의 파라미터이다.

1. min_impurity_decrease : 노드를 분할하기 위한 불순도 감소 최소량 지정하는 매개변수
2. max_depth : 트리의 깊이이 제한하는 매개변수
3. min_samples_split : 노드를 나누기 위한 최소 샘플 수를 지정하는 매개변수


```python
# make the set of parameters what we will experiment with
params = {'min_impurity_decrease' : np.arange(0.0001, 0.001, 0.0001),
         'max_depth' : range(5,20,1),
         'min_samples_split' : range(2,100,10)
         }
```

* arange(n,m,k)는 n부터 m까지 k씩 증가하는 등차수열이 되는 배열을 만든다. 단, m은 포함하지 않는다.
* range(n,m,k)는 arange(n,m,k)와 동일하지만, 정수만 사용 가능하다.

위의 파라미터들의 조합을 모두 구해보면 나올 수 있는 경우의 수는 다음과 같다.

$$
'min\_impurity\_decrease' : \frac{0.001 - 0.0001}{0.0001} = 9 \\
'max\_depth' : \frac{20-5}{1} = 15 \\
'min\_samples\_split' : \frac{100-2}{10} = 9.8 \Rightarrow 10 \\
\Rightarrow 9 \times 15 \times 10 = 1350
$$

기본적으로 총 1350개의 경우의 수가 만들어진다. 여기서 5-폴드 교차 검증을 한다면 $1350 \times 5 = 6750$개의 모델이 만들어진다. 


```python
# make grid search object and test by using grid search
gs = GridSearchCV(DecisionTreeClassifier(random_state=42),params,n_jobs=None)
gs.fit(train_input, train_target)
```




    GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                 param_grid={'max_depth': range(5, 20),
                             'min_impurity_decrease': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,
           0.0009]),
                             'min_samples_split': range(2, 100, 10)})




```python
# the best parameters
print(gs.best_params_)
```

    {'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}
    


```python
# the best cross validation score
print(np.max(gs.cv_results_['mean_test_score']))
```

    0.8683865773302731
    

3가지 파라미터에 대해서 그리드 서치를 진행한 결과는 다음과 같다. 
'max_depth'=14, 'min_impurity_decrease'=0.0004, 'min_samples_split'= 12


# 하이퍼파라미터 튜닝 - 랜덤 서치

그리드 서치를 위해서 매개변수를 지정할 때, arange()와 range() 함수를 이용했기 때문에 매개변수가 일정 간격으로 주어졌다. 이번에는 확률적으로 뽑는 방법인 랜덤 서치를 실습해보자.

## Step1. 확률 분포 클래스 
먼저, 싸이파이 라이브러리의 stats 서브 패키지 안에 있는 uniform과 randint라는 확률 분포 클래스를 불러온다. 두 클래스 모두 주어진 범위에서 고르게 값을 뽑는다. 이를 '균등 분포에서 샘플링한다.'라고 말한다. randint는 정숫값을 uniform은 실숫값을 뽑는다. 다음의 예제로 어떻게 사용하는지 익혀보자.


```python
# import class
from scipy.stats import uniform, randint
```


```python
# example
rgen = randint(0,10) # sampling number from 0 to 9
np.unique(rgen.rvs(1000), return_counts=True) # sampling 1000 numbers and showing counts for each number from 0 to 9
```




    (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
     array([ 90, 107, 114,  86, 114, 108, 102, 100,  97,  82], dtype=int64))



## Step2. 매개변수 설정

확률 분포 클래스를 이용해서 탐색할 매개변수의 범위를 설정한다.


```python
# make the set of parameters what we will experiment with
params = {'min_impurity_decrease' : uniform(0.0001,0.001),
         'max_depth' : randint(20,50),
         'min_samples_split' : randint(2,25),
         'min_samples_leaf' : randint(1,25)
         }
```


## Step3. 랜덤 서치 클래스 



```python
# make grid search object and test by using random search
from sklearn.model_selection import RandomizedSearchCV
gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=None, random_state=42)
gs.fit(train_input, train_target)
```




    RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                       n_iter=100,
                       param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000026A39B9AD48>,
                                            'min_impurity_decrease': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000026A39B9AA08>,
                                            'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000026A39BA0588>,
                                            'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000026A39B9A148>},
                       random_state=42)




```python
# check parameter list
n = len(gs.cv_results_['mean_test_score'])
result = gs.cv_results_['params']
result = [[i+1, result[i]] for i in range(n)]
for row in result:
    print(row)
```

    [1, {'max_depth': 26, 'min_impurity_decrease': 0.0008965429868602329, 'min_samples_leaf': 15, 'min_samples_split': 12}]
    [2, {'max_depth': 27, 'min_impurity_decrease': 0.0006986584841970366, 'min_samples_leaf': 7, 'min_samples_split': 20}]
    [3, {'max_depth': 42, 'min_impurity_decrease': 0.00015808361216819946, 'min_samples_leaf': 24, 'min_samples_split': 22}]
    [4, {'max_depth': 23, 'min_impurity_decrease': 0.0002428668179219408, 'min_samples_leaf': 3, 'min_samples_split': 23}]
    [5, {'max_depth': 40, 'min_impurity_decrease': 0.0010699098521619944, 'min_samples_leaf': 12, 'min_samples_split': 7}]
    [6, {'max_depth': 21, 'min_impurity_decrease': 0.0002818249672071006, 'min_samples_leaf': 21, 'min_samples_split': 2}]
    [7, {'max_depth': 31, 'min_impurity_decrease': 0.000711653160488281, 'min_samples_leaf': 12, 'min_samples_split': 18}]
    [8, {'max_depth': 46, 'min_impurity_decrease': 0.0007118528947223795, 'min_samples_leaf': 10, 'min_samples_split': 17}]
    [9, {'max_depth': 34, 'min_impurity_decrease': 0.000556069984217036, 'min_samples_leaf': 15, 'min_samples_split': 20}]
    [10, {'max_depth': 31, 'min_impurity_decrease': 0.0006142344384136117, 'min_samples_leaf': 3, 'min_samples_split': 6}]
    [11, {'max_depth': 38, 'min_impurity_decrease': 0.0007803075385877798, 'min_samples_leaf': 9, 'min_samples_split': 8}]
    [12, {'max_depth': 37, 'min_impurity_decrease': 0.0010488855372533332, 'min_samples_leaf': 14, 'min_samples_split': 19}]
    [13, {'max_depth': 45, 'min_impurity_decrease': 0.0004046137691733707, 'min_samples_leaf': 21, 'min_samples_split': 3}]
    [14, {'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}]
    [15, {'max_depth': 48, 'min_impurity_decrease': 0.0009331949117361644, 'min_samples_leaf': 3, 'min_samples_split': 15}]
    [16, {'max_depth': 36, 'min_impurity_decrease': 0.0003587799816000169, 'min_samples_leaf': 8, 'min_samples_split': 5}]
    [17, {'max_depth': 21, 'min_impurity_decrease': 0.0005251558744912447, 'min_samples_leaf': 22, 'min_samples_split': 11}]
    [18, {'max_depth': 23, 'min_impurity_decrease': 0.00028485445552552704, 'min_samples_leaf': 18, 'min_samples_split': 13}]
    [19, {'max_depth': 21, 'min_impurity_decrease': 0.0004951502360018144, 'min_samples_leaf': 4, 'min_samples_split': 15}]
    [20, {'max_depth': 35, 'min_impurity_decrease': 0.0004265407688058354, 'min_samples_leaf': 14, 'min_samples_split': 24}]
    [21, {'max_depth': 47, 'min_impurity_decrease': 0.00014522728891053807, 'min_samples_leaf': 8, 'min_samples_split': 22}]
    [22, {'max_depth': 35, 'min_impurity_decrease': 0.0008473201101373809, 'min_samples_leaf': 15, 'min_samples_split': 22}]
    [23, {'max_depth': 43, 'min_impurity_decrease': 0.0004567533266935893, 'min_samples_leaf': 13, 'min_samples_split': 10}]
    [24, {'max_depth': 48, 'min_impurity_decrease': 0.0009021969807540397, 'min_samples_leaf': 1, 'min_samples_split': 8}]
    [25, {'max_depth': 28, 'min_impurity_decrease': 0.0008722447692966575, 'min_samples_leaf': 12, 'min_samples_split': 9}]
    [26, {'max_depth': 43, 'min_impurity_decrease': 0.00011407982271508446, 'min_samples_leaf': 19, 'min_samples_split': 18}]
    [27, {'max_depth': 27, 'min_impurity_decrease': 0.0008290071680409874, 'min_samples_leaf': 1, 'min_samples_split': 6}]
    [28, {'max_depth': 29, 'min_impurity_decrease': 0.0004584657285442726, 'min_samples_leaf': 9, 'min_samples_split': 8}]
    [29, {'max_depth': 28, 'min_impurity_decrease': 0.0007232981268275579, 'min_samples_leaf': 2, 'min_samples_split': 2}]
    [30, {'max_depth': 35, 'min_impurity_decrease': 0.00047081825219826636, 'min_samples_leaf': 24, 'min_samples_split': 6}]
    [31, {'max_depth': 22, 'min_impurity_decrease': 0.0006912977877077272, 'min_samples_leaf': 22, 'min_samples_split': 4}]
    [32, {'max_depth': 20, 'min_impurity_decrease': 0.00048292687475378986, 'min_samples_leaf': 15, 'min_samples_split': 15}]
    [33, {'max_depth': 22, 'min_impurity_decrease': 0.0008607850486168975, 'min_samples_leaf': 23, 'min_samples_split': 15}]
    [34, {'max_depth': 26, 'min_impurity_decrease': 0.00014043358953843134, 'min_samples_leaf': 15, 'min_samples_split': 16}]
    [35, {'max_depth': 45, 'min_impurity_decrease': 0.00012541912674409519, 'min_samples_leaf': 13, 'min_samples_split': 20}]
    [36, {'max_depth': 26, 'min_impurity_decrease': 0.0005753702231821118, 'min_samples_leaf': 4, 'min_samples_split': 6}]
    [37, {'max_depth': 42, 'min_impurity_decrease': 0.0007044173792778173, 'min_samples_leaf': 15, 'min_samples_split': 12}]
    [38, {'max_depth': 48, 'min_impurity_decrease': 0.00032879816549162246, 'min_samples_leaf': 7, 'min_samples_split': 20}]
    [39, {'max_depth': 41, 'min_impurity_decrease': 0.0009804678390152577, 'min_samples_leaf': 10, 'min_samples_split': 14}]
    [40, {'max_depth': 49, 'min_impurity_decrease': 0.0007334037565104235, 'min_samples_leaf': 6, 'min_samples_split': 13}]
    [41, {'max_depth': 31, 'min_impurity_decrease': 0.0005165099478703662, 'min_samples_leaf': 11, 'min_samples_split': 24}]
    [42, {'max_depth': 47, 'min_impurity_decrease': 0.0004562978380769749, 'min_samples_leaf': 1, 'min_samples_split': 2}]
    [43, {'max_depth': 44, 'min_impurity_decrease': 0.0007476901205413623, 'min_samples_leaf': 20, 'min_samples_split': 14}]
    [44, {'max_depth': 28, 'min_impurity_decrease': 0.000404781258158029, 'min_samples_leaf': 6, 'min_samples_split': 9}]
    [45, {'max_depth': 46, 'min_impurity_decrease': 0.000517411003148779, 'min_samples_leaf': 5, 'min_samples_split': 2}]
    [46, {'max_depth': 38, 'min_impurity_decrease': 0.0003694123337985215, 'min_samples_leaf': 24, 'min_samples_split': 16}]
    [47, {'max_depth': 46, 'min_impurity_decrease': 0.00042320293202075524, 'min_samples_leaf': 24, 'min_samples_split': 10}]
    [48, {'max_depth': 39, 'min_impurity_decrease': 0.000463629602379294, 'min_samples_leaf': 17, 'min_samples_split': 21}]
    [49, {'max_depth': 31, 'min_impurity_decrease': 0.0003517822958253642, 'min_samples_leaf': 2, 'min_samples_split': 4}]
    [50, {'max_depth': 36, 'min_impurity_decrease': 0.0002480869299533999, 'min_samples_leaf': 24, 'min_samples_split': 18}]
    [51, {'max_depth': 46, 'min_impurity_decrease': 0.0007095643339798969, 'min_samples_leaf': 2, 'min_samples_split': 23}]
    [52, {'max_depth': 42, 'min_impurity_decrease': 0.00037864646423661145, 'min_samples_leaf': 1, 'min_samples_split': 2}]
    [53, {'max_depth': 38, 'min_impurity_decrease': 0.0007807054515547669, 'min_samples_leaf': 21, 'min_samples_split': 13}]
    [54, {'max_depth': 45, 'min_impurity_decrease': 0.0010856504541106008, 'min_samples_leaf': 23, 'min_samples_split': 5}]
    [55, {'max_depth': 42, 'min_impurity_decrease': 0.0008616196153287177, 'min_samples_leaf': 17, 'min_samples_split': 7}]
    [56, {'max_depth': 43, 'min_impurity_decrease': 0.0005703006344460385, 'min_samples_leaf': 2, 'min_samples_split': 7}]
    [57, {'max_depth': 41, 'min_impurity_decrease': 0.0006357746840747585, 'min_samples_leaf': 16, 'min_samples_split': 17}]
    [58, {'max_depth': 20, 'min_impurity_decrease': 0.00025071754396542947, 'min_samples_leaf': 6, 'min_samples_split': 17}]
    [59, {'max_depth': 48, 'min_impurity_decrease': 0.0009583588048137199, 'min_samples_leaf': 4, 'min_samples_split': 20}]
    [60, {'max_depth': 45, 'min_impurity_decrease': 0.0006120930582992811, 'min_samples_leaf': 19, 'min_samples_split': 21}]
    [61, {'max_depth': 26, 'min_impurity_decrease': 0.0002743664290049914, 'min_samples_leaf': 1, 'min_samples_split': 9}]
    [62, {'max_depth': 26, 'min_impurity_decrease': 0.0010367299887367345, 'min_samples_leaf': 1, 'min_samples_split': 12}]
    [63, {'max_depth': 47, 'min_impurity_decrease': 0.0008352161192407722, 'min_samples_leaf': 18, 'min_samples_split': 24}]
    [64, {'max_depth': 49, 'min_impurity_decrease': 0.0007957843993450823, 'min_samples_leaf': 7, 'min_samples_split': 17}]
    [65, {'max_depth': 45, 'min_impurity_decrease': 0.0010821683433294357, 'min_samples_leaf': 20, 'min_samples_split': 18}]
    [66, {'max_depth': 21, 'min_impurity_decrease': 0.0010962536997579243, 'min_samples_leaf': 12, 'min_samples_split': 6}]
    [67, {'max_depth': 24, 'min_impurity_decrease': 0.0009826363431893396, 'min_samples_leaf': 23, 'min_samples_split': 10}]
    [68, {'max_depth': 28, 'min_impurity_decrease': 0.0004492095746126609, 'min_samples_leaf': 16, 'min_samples_split': 17}]
    [69, {'max_depth': 22, 'min_impurity_decrease': 0.0009563242918780925, 'min_samples_leaf': 22, 'min_samples_split': 2}]
    [70, {'max_depth': 43, 'min_impurity_decrease': 0.0009509284487675128, 'min_samples_leaf': 17, 'min_samples_split': 9}]
    [71, {'max_depth': 23, 'min_impurity_decrease': 0.0009985541885270792, 'min_samples_leaf': 20, 'min_samples_split': 4}]
    [72, {'max_depth': 35, 'min_impurity_decrease': 0.00020147154286603213, 'min_samples_leaf': 3, 'min_samples_split': 19}]
    [73, {'max_depth': 33, 'min_impurity_decrease': 0.0006487337893665862, 'min_samples_leaf': 22, 'min_samples_split': 4}]
    [74, {'max_depth': 35, 'min_impurity_decrease': 0.0010944574626108208, 'min_samples_leaf': 4, 'min_samples_split': 2}]
    [75, {'max_depth': 23, 'min_impurity_decrease': 0.0003372490874968001, 'min_samples_leaf': 21, 'min_samples_split': 17}]
    [76, {'max_depth': 39, 'min_impurity_decrease': 0.00046646878458285994, 'min_samples_leaf': 8, 'min_samples_split': 8}]
    [77, {'max_depth': 22, 'min_impurity_decrease': 0.0007576128923003434, 'min_samples_leaf': 1, 'min_samples_split': 17}]
    [78, {'max_depth': 31, 'min_impurity_decrease': 0.00060881407683876, 'min_samples_leaf': 22, 'min_samples_split': 24}]
    [79, {'max_depth': 41, 'min_impurity_decrease': 0.0003439896433790836, 'min_samples_leaf': 6, 'min_samples_split': 7}]
    [80, {'max_depth': 32, 'min_impurity_decrease': 0.0005867421529594551, 'min_samples_leaf': 8, 'min_samples_split': 3}]
    [81, {'max_depth': 40, 'min_impurity_decrease': 0.0006026370931051921, 'min_samples_leaf': 15, 'min_samples_split': 2}]
    [82, {'max_depth': 24, 'min_impurity_decrease': 0.0003301852682415553, 'min_samples_leaf': 16, 'min_samples_split': 20}]
    [83, {'max_depth': 23, 'min_impurity_decrease': 0.00012431596643145386, 'min_samples_leaf': 17, 'min_samples_split': 18}]
    [84, {'max_depth': 31, 'min_impurity_decrease': 0.0010404585843529143, 'min_samples_leaf': 14, 'min_samples_split': 22}]
    [85, {'max_depth': 25, 'min_impurity_decrease': 0.0004701587002554444, 'min_samples_leaf': 9, 'min_samples_split': 6}]
    [86, {'max_depth': 43, 'min_impurity_decrease': 0.0004307503046705137, 'min_samples_leaf': 14, 'min_samples_split': 22}]
    [87, {'max_depth': 22, 'min_impurity_decrease': 0.0010803315837160457, 'min_samples_leaf': 20, 'min_samples_split': 22}]
    [88, {'max_depth': 42, 'min_impurity_decrease': 0.0003684748568901568, 'min_samples_leaf': 3, 'min_samples_split': 19}]
    [89, {'max_depth': 44, 'min_impurity_decrease': 0.0004946914668094723, 'min_samples_leaf': 22, 'min_samples_split': 4}]
    [90, {'max_depth': 27, 'min_impurity_decrease': 0.0001704161308495439, 'min_samples_leaf': 18, 'min_samples_split': 16}]
    [91, {'max_depth': 41, 'min_impurity_decrease': 0.0004586467812961639, 'min_samples_leaf': 10, 'min_samples_split': 3}]
    [92, {'max_depth': 45, 'min_impurity_decrease': 0.0008407686177542045, 'min_samples_leaf': 1, 'min_samples_split': 10}]
    [93, {'max_depth': 30, 'min_impurity_decrease': 0.0008089109969101186, 'min_samples_leaf': 7, 'min_samples_split': 11}]
    [94, {'max_depth': 42, 'min_impurity_decrease': 0.0005197808564462765, 'min_samples_leaf': 18, 'min_samples_split': 14}]
    [95, {'max_depth': 47, 'min_impurity_decrease': 0.0006113423988609378, 'min_samples_leaf': 4, 'min_samples_split': 14}]
    [96, {'max_depth': 39, 'min_impurity_decrease': 0.0007499639307777652, 'min_samples_leaf': 14, 'min_samples_split': 17}]
    [97, {'max_depth': 33, 'min_impurity_decrease': 0.0009900053418175664, 'min_samples_leaf': 23, 'min_samples_split': 16}]
    [98, {'max_depth': 47, 'min_impurity_decrease': 0.0006788648955075588, 'min_samples_leaf': 23, 'min_samples_split': 23}]
    [99, {'max_depth': 38, 'min_impurity_decrease': 0.0005655980181324602, 'min_samples_leaf': 22, 'min_samples_split': 23}]
    [100, {'max_depth': 36, 'min_impurity_decrease': 0.00013734818874921442, 'min_samples_leaf': 6, 'min_samples_split': 16}]
    

샘플링 횟수는 랜덤 서치 클래스인 RandomizedSearchCV의 n_iter 매개변수에 지정한다. 각각의 파라미터를 각각의 범위 내에서 총 100가지의 경우의 수를 추출해서 랜덤 서치를 진행한다. 그리드 서치보다 훨씬 교차 검증 수를 줄이면서 넓은 영역을 효과적으로 탐색할 수 있다.

## Step4. 최적의 하이퍼파라미터 확인하기


```python
# the best parameter
print(gs.best_params_)
```

    {'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}
    


```python
# the best cross validation score
print(np.max(gs.cv_results_['mean_test_score']))
```

    0.8695428296438884
    


```python
# train set score
dt = gs.best_estimator_
print(dt.score(test_input, test_target))
```

    0.86
    
